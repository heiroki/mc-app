# backend/main.pyï¼ˆä¿®æ­£ç‰ˆï¼‰

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import logging
import sys

# ãƒ­ã‚°è¨­å®šã‚’æœ€åˆã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from logging_config import setup_logging

# ãã®ä»–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import APP_VERSION, APP_NAME
from database import init_db
from inference_manager import get_inference_manager

# ãƒ«ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import routes
import ai_routes
import wc_routes

logger = logging.getLogger(__name__)

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
app = FastAPI(
    title=APP_NAME,
    version=APP_VERSION,
    description="Desktop AI Application with Local LLM"
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒ«ãƒ¼ã‚¿ãƒ¼ç™»éŒ²
app.include_router(ai_routes.router)
app.include_router(routes.router)
app.include_router(wc_routes.router)

@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®å‡¦ç†"""
    logger.info("=" * 60)
    logger.info("ğŸš€ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ä¸­...")
    logger.info("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    try:
        init_db()
    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•—: {e}")
        sys.exit(1)
    
    # æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    try:
        inference_manager = get_inference_manager()
        logger.info("âœ… æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        logger.error(f"âŒ æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
        sys.exit(1)
    
    logger.info("âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•å®Œäº†")

@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚ã®å‡¦ç†"""
    logger.info("ğŸ›‘ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ä¸­...")
    
    from inference_manager import inference_manager
    if inference_manager:
        inference_manager.shutdown()
    
    logger.info("âœ… ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å®Œäº†")

@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    from inference_manager import inference_manager
    
    return {
        "status": "ok",
        "version": APP_VERSION,
        "model_loaded": inference_manager is not None and inference_manager.llm is not None
    }

if __name__ == "__main__":
    import uvicorn
    from config import API_HOST, API_PORT
    
    uvicorn.run(app, host=API_HOST, port=API_PORT, log_level="info")
